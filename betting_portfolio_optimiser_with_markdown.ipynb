{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd625cd-7d3c-4911-ab1d-31860b17ee29",
   "metadata": {},
   "source": [
    "# QUBO Portfolio Optimisation for a Single Football Match\n",
    "\n",
    "This notebook demonstrates a **portfolio optimisation engine for sportsbook bets** using a QUBO / Ising formulation and the ORBIT probabilistic simulator.\n",
    "\n",
    "\n",
    "Our solution focuses on **optimising a portfolio of sportsbook bets according to the user’s risk appetite**, rather than searching for strict risk-free arbitrage.\n",
    "\n",
    "- Each bet is treated as a **node** in a graph, with a weight equal to its **expected value (EV)** based on our probability estimate and the market odds.\n",
    "- **Edges** represent **correlation or overlap between bets** – for example, multiple bets depending on the same match outcome or scoreline.\n",
    "- The optimisation goal is to select a subset of bets that **maximises total positive alpha** while penalising portfolios that are **over-exposed to the same risks**.\n",
    "\n",
    "In other words, we help a bettor (or trading desk) allocate their bankroll intelligently:  \n",
    "**focus on value, avoid redundant risk, and respect a chosen risk appetite.**\n",
    "\n",
    "Although we demonstrate the method on sports betting, the underlying optimisation framework is general.  \n",
    "Treating positions as nodes, their relationships as edges, and minimising an energy function to pick a portfolio can be applied in other financial settings too – for example **options selection**, **trades within the same asset class**, or **small diversified portfolios** where interactions matter.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Structure of this notebook\n",
    "\n",
    "1. **Data preparation**  \n",
    "   - Load and clean a set of markets for a single football match.\n",
    "   - In our case we are using a recent game between FC Barcelona and Atlético Madrid.\n",
    "   - Build a time series of odds and implied probabilities for multiple markets.\n",
    "\n",
    "2. **QUBO formulation (portfolio objective)**  \n",
    "   - Compute the **expected value (EV)** of each bet.  \n",
    "   - Build a **QUBO energy function** where:  \n",
    "     - linear terms encode the value of including a discrete allocation of each bet;\n",
    "     - quadratic terms encode correlation / overlap penalties between bets. Deviations between the sum of the correlations and the user's risk appetite penalises the energy function.\n",
    "\n",
    "3. **Parameter Coefficient Estimation**\n",
    "   - Implement a constraint estimation algorithm to determine the risk appetite.\n",
    "   - This helps optimise the portfolio while taking into account risks linked to the betting markets \n",
    "\n",
    "4. **Brute-force validation (small N)**  \n",
    "   - For a modest number of markets (e.g. N ≈ 20), exhaustively evaluate all 2^N portfolios.  \n",
    "   - Use this to obtain the exact ground state and validate the quality of ORBIT’s solution.\n",
    "   - Analysis of the brute-force algorithm reveals what we expected, a correct yet very slow answer.\n",
    "   - At scale, this solution is not suitable due to the high number of potential portfolios that exist.\n",
    "\n",
    "5. **QUBO → Ising mapping**  \n",
    "   - Map the QUBO to an Ising model with couplings J and fields h.\n",
    "   - Normalisation of the J and h fiels in order to avoid potential overflow.\n",
    "\n",
    "6. **Two-stage preprocessing**\n",
    "   - First stage of preprocessing eliminates poor candidates and identifies promising subsets. This helps create a reduced problem.\n",
    "   - Second stage of preprocessing prepares the promising subsets for the various optimisation methods.\n",
    "\n",
    "7. **Ising model optimisation using ORBIT**\n",
    "   - Run the ORBIT simulator to approximately minimise the Ising energy.  \n",
    "   - Decode the resulting spin configuration back into a set of bets.\n",
    "\n",
    "8. **Comparison and interpretation**  \n",
    "   - Multiple classical solutions exist, with two of the more famous ones being simulated annealing and greedy algorithms.\n",
    "   - Both of these heuristic models have their pros and cons.\n",
    "   - Greedy algorithms reach sub-second speeds but struggle to get to the ground state.\n",
    "   - At scale, greedy algorithms can also fall prey to being stuck in local optima without noticing it.\n",
    "   - Simulated annealing find the optimal betting pattern at comparable speeds to that of probabilistic computing.\n",
    "   - However it cannot handle the actual size of sports betting markets, as handling simply over 50 markets causes the algorithm to run extremely slowly.\n",
    "   - ORBIT's optimisation algorithm performs decently given the strong constraints imposed on it. It can handle much larger markets than classical algorithms as well.\n",
    "   - Though speed seems to be an issue on the simulator, with access to direct hardware and larger markets, the value of this solution becomes very clear.\n",
    "   - Many classical algorithms perform decently with reduced constraints and in smaller size markets. However, at scale, only ORBIT's probabilistic computing simulator can handle the workload that would be demanded in the industry.\n",
    "\n",
    "\n",
    "The emphasis is not on speed or large-scale deployment in this notebook, but on a **clear, end-to-end demonstration** of how a realistic optimisation problem is encoded as a QUBO and solved using probabilistic computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f4ef9576-822e-4440-a125-3a26855417b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import time\n",
    "import orbit \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3b08027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path.cwd()\n",
    "DATA = 'data'\n",
    "FILE = 'odds_long.csv'\n",
    "ALPHA = 1.0\n",
    "BETA = 5.0\n",
    "A = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e4c62",
   "metadata": {},
   "source": [
    "## Loading in and preparing the data from the odds API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv data stored from the API\n",
    "import pandas as pd\n",
    "# Changing this variable should be enough to change the data used in the notebook\n",
    "bar_v_atl_data = 'data/output-bar-v-atl-shortened-live-and-pre-match.csv'\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Melt the dataframe: keep timestamp as id, convert all odds columns to rows\n",
    "    df_long = df.melt(\n",
    "        id_vars=['timestamp'],\n",
    "        var_name='market',\n",
    "        value_name='odds'\n",
    "    )\n",
    "    \n",
    "    # Calculate implied probability: p = 1 / odds\n",
    "    # This represents the probability implied by the decimal odds\n",
    "    df_long['implied_prob'] = 1.0 / df_long['odds']\n",
    "\n",
    "    # Calculate expected value: EV = p * odds - 1\n",
    "    # Later the sign will be flipped to match the QUBO energy function\n",
    "    df_long['expected_value'] = df_long['implied_prob'] * df_long['odds']\n",
    "    \n",
    "    # Calculate the correlation matrix of the implied probabilities\n",
    "    corr_df = df_long.pivot_table(\n",
    "    index='timestamp',\n",
    "    columns='market',\n",
    "    values='implied_prob'\n",
    "    ).corr()\n",
    "    \n",
    "    return df_long, corr_df\n",
    "\n",
    "df, bar_v_atl_corr = load_and_prepare_data(bar_v_atl_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fbf282",
   "metadata": {},
   "source": [
    "## QUBO formulation: betting portfolio as a binary optimisation problem\n",
    "\n",
    "We model the selection of bets as a **binary vector**:\n",
    "\n",
    "- Let $x_i \\in \\set{0,1}$ indicate whether bet $i$ is included in the portfolio.  \n",
    "- For each bet, we define an **expected value per unit stake**:\n",
    "  $$\\text{EV}_i = p_i \\cdot \\text{odds}_i$$\n",
    "  where $p_i$ is our (subjective or model-based) probability for that outcome and $\\text{odds}_i$ is the decimal odds.\n",
    "\n",
    "We model the risk appetite as a maximum volatility, $\\sigma_{\\max}$. The true portfolio variance is modelled by\n",
    "$$\\sigma^2(\\mathbf{x}) = \\mathbf{x}^\\top \\Sigma \\mathbf{x} = \\sum_{i,j} \\Sigma_{i,j}x_i x_j$$\n",
    "\n",
    "To enforce allocation restraints, we ensure $\\sum_i x_i \\le A$ via a penalty term:\n",
    "$$(A - \\sum_i x_i)^2 = A^2 - 2A \\sum_i x_i + \\sum_{i,j}x_i x_j$$\n",
    "\n",
    "Combining the expected value objective, the risk penalty, and the allocation restraint, we obtain:\n",
    "$$\\begin{align*}\n",
    "E_{\\text{QUBO}}(x) &= - \\alpha \\sum\\limits_{i} \\mu_{i} x_{i} + \\beta \\sum\\limits_{i,j} \\Sigma_{i,j}x_{i} x_{j} + A^{2} - 2A \\sum\\limits_{i} x_{i} + \\sum\\limits_{i,j}x_{i} x_{j} \\\\\n",
    "&= - \\sum\\limits_{i}(\\alpha \\mu_{i} + 2A)x_{i} + \\sum\\limits_{i,j}(\\beta \\Sigma_{i, j} + 1)x_{i}x_{J} + A^{2}\n",
    "\\end{align*}$$\n",
    "\n",
    "We then construct a **QUBO energy function** of the form:\n",
    "$$E_{\\text{QUBO}}(x) = - \\sum_i \\mu_i x_i + \\sum_{i<j} Q_{ij} x_i x_j + \\text{const}$$\n",
    "\n",
    "The **linear term** $\\mu_i$ is taken as\n",
    "$$\\mu_i = \\alpha \\text{EV}_i + 2A$$\n",
    "so that bets with higher expected value contribute **lower energy** when selected (since we minimise $E$).\n",
    "\n",
    "The **quadratic term** $Q_{ij}$ encodes **correlations or overlaps** between bets:\n",
    "  - If two bets load on the same underlying match or outcome, a positive $Q_{ij}$ penalises taking them together.\n",
    "  - If two bets are relatively independent, $Q_{ij}$ will be small.\n",
    "\n",
    "The linear and quadratic terms both include elements of the allocation restraint to penalise exceeding $A$, too.\n",
    "\n",
    "The overall effect is:\n",
    "\n",
    "- Portfolios with **many high-EV bets** have **low linear energy**.  \n",
    "- Portfolios that are **over-exposed to the same outcome** incur **quadratic penalties**.  \n",
    "- Portfolios are penalised for exceeding the allocation constraint.\n",
    "\n",
    "By minimising $E_{\\text{QUBO}}(x)$ according to various $\\alpha, \\beta$, we search for a portfolio that balances **value (alpha)** and **risk concentration**, consistent with the user’s risk appetite and allocation size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1168d106-70ea-47fc-b50f-2c3df1b4009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_value(p, odds):\n",
    "    \"\"\"\n",
    "    Expected profit per unit stake:\n",
    "    EV = p * odds\n",
    "    \"\"\"\n",
    "    return p * odds\n",
    "\n",
    "def portfolio_energy_qubo(x, mu, cov, alpha, beta, A):\n",
    "    \"\"\"\n",
    "    QUBO energy:\n",
    "    x : 1D numpy array of 0/1 of length N\n",
    "    mu : 1D numpy array of expected values of length N\n",
    "    cov : 2D numpy array (NxN) covariance matrix\n",
    "    alpha : float, weight for linear term\n",
    "    beta : float, weight for quadratic penalty\n",
    "    A : float, target allocation (max allocation size)\n",
    "    \"\"\"\n",
    "    linear = np.dot((alpha * mu + 2 * A), x)\n",
    "    quadratic = x.T @ (beta * cov + 1) @ x\n",
    "    return - linear + quadratic + A**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c34daafb-322a-4599-9fa9-8008cab1ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Correlation Matrix (20×20) ===\n",
      "market             money_line_away  money_line_draw  money_line_home  \\\n",
      "market                                                                 \n",
      "money_line_away           1.000000         0.679587        -0.900308   \n",
      "money_line_draw           0.679587         1.000000        -0.656940   \n",
      "money_line_home          -0.900308        -0.656940         1.000000   \n",
      "spread_-0.25_away         0.978194         0.789322        -0.932326   \n",
      "spread_-0.25_home        -0.913947        -0.604573         0.985406   \n",
      "spread_-0.5_away          0.972703         0.808371        -0.923486   \n",
      "spread_-0.5_home         -0.896765        -0.678509         0.992860   \n",
      "spread_-0.75_away         0.972731         0.814077        -0.915507   \n",
      "spread_-0.75_home        -0.907498        -0.681312         0.991780   \n",
      "spread_-1.0_away          0.966216         0.815460        -0.905421   \n",
      "spread_-1.0_home         -0.926131        -0.722805         0.983098   \n",
      "spread_-1.25_away         0.949878         0.847705        -0.878698   \n",
      "spread_-1.25_home        -0.928006        -0.698953         0.973018   \n",
      "spread_-1.5_away          0.938733         0.855909        -0.857074   \n",
      "spread_-1.5_home         -0.919896        -0.693628         0.964166   \n",
      "spread_-1.75_away         0.900841         0.888270        -0.820250   \n",
      "spread_-1.75_home        -0.926185        -0.681772         0.953211   \n",
      "spread_0.0_away           0.990212         0.728659        -0.927893   \n",
      "spread_0.0_home          -0.920043        -0.522398         0.967879   \n",
      "spread_0.25_away          0.991884         0.712339        -0.920500   \n",
      "spread_0.25_home         -0.910065        -0.457628         0.940308   \n",
      "totals_4.5_over           0.197777        -0.287524        -0.178507   \n",
      "totals_4.5_under          0.171263         0.417499        -0.097829   \n",
      "\n",
      "market             spread_-0.25_away  spread_-0.25_home  spread_-0.5_away  \\\n",
      "market                                                                      \n",
      "money_line_away             0.978194          -0.913947          0.972703   \n",
      "money_line_draw             0.789322          -0.604573          0.808371   \n",
      "money_line_home            -0.932326           0.985406         -0.923486   \n",
      "spread_-0.25_away           1.000000          -0.926574          0.996632   \n",
      "spread_-0.25_home          -0.926574           1.000000         -0.917990   \n",
      "spread_-0.5_away            0.996632          -0.917990          1.000000   \n",
      "spread_-0.5_home           -0.935387           0.986090         -0.927364   \n",
      "spread_-0.75_away           0.994303          -0.911216          0.995460   \n",
      "spread_-0.75_home          -0.943482           0.985924         -0.936631   \n",
      "spread_-1.0_away            0.988913          -0.900528          0.991942   \n",
      "spread_-1.0_home           -0.959938           0.978448         -0.955592   \n",
      "spread_-1.25_away           0.980607          -0.866884          0.985348   \n",
      "spread_-1.25_home          -0.952412           0.976273         -0.949431   \n",
      "spread_-1.5_away            0.970930          -0.845004          0.976907   \n",
      "spread_-1.5_home           -0.943636           0.969746         -0.942283   \n",
      "spread_-1.75_away           0.947950          -0.796782          0.954737   \n",
      "spread_-1.75_home          -0.941288           0.962704         -0.940423   \n",
      "spread_0.0_away             0.992284          -0.935866          0.987680   \n",
      "spread_0.0_home            -0.909078           0.989413         -0.896378   \n",
      "spread_0.25_away            0.990265          -0.924535          0.983438   \n",
      "spread_0.25_home           -0.881093           0.974237         -0.868170   \n",
      "totals_4.5_over             0.111964          -0.204623          0.085434   \n",
      "totals_4.5_under            0.211943          -0.085567          0.230288   \n",
      "\n",
      "market             spread_-0.5_home  spread_-0.75_away  spread_-0.75_home  \\\n",
      "market                                                                      \n",
      "money_line_away           -0.896765           0.972731          -0.907498   \n",
      "money_line_draw           -0.678509           0.814077          -0.681312   \n",
      "money_line_home            0.992860          -0.915507           0.991780   \n",
      "spread_-0.25_away         -0.935387           0.994303          -0.943482   \n",
      "spread_-0.25_home          0.986090          -0.911216           0.985924   \n",
      "spread_-0.5_away          -0.927364           0.995460          -0.936631   \n",
      "spread_-0.5_home           1.000000          -0.920997           0.992358   \n",
      "spread_-0.75_away         -0.920997           1.000000          -0.928520   \n",
      "spread_-0.75_home          0.992358          -0.928520           1.000000   \n",
      "spread_-1.0_away          -0.907923           0.993587          -0.922258   \n",
      "spread_-1.0_home           0.985790          -0.953380           0.989796   \n",
      "spread_-1.25_away         -0.883279           0.988793          -0.897287   \n",
      "spread_-1.25_home          0.974404          -0.948870           0.982667   \n",
      "spread_-1.5_away          -0.862218           0.981680          -0.878071   \n",
      "spread_-1.5_home           0.965869          -0.942871           0.975781   \n",
      "spread_-1.75_away         -0.828178           0.959566          -0.843250   \n",
      "spread_-1.75_home          0.952718          -0.943319           0.964892   \n",
      "spread_0.0_away           -0.928319           0.985894          -0.937493   \n",
      "spread_0.0_home            0.964620          -0.889801           0.966474   \n",
      "spread_0.25_away          -0.920967           0.980005          -0.929178   \n",
      "spread_0.25_home           0.933469          -0.863234           0.937791   \n",
      "totals_4.5_over           -0.155452           0.063231          -0.143533   \n",
      "totals_4.5_under          -0.112882           0.260093          -0.134650   \n",
      "\n",
      "market             spread_-1.0_away  ...  spread_-1.5_away  spread_-1.5_home  \\\n",
      "market                               ...                                       \n",
      "money_line_away            0.966216  ...          0.938733         -0.919896   \n",
      "money_line_draw            0.815460  ...          0.855909         -0.693628   \n",
      "money_line_home           -0.905421  ...         -0.857074          0.964166   \n",
      "spread_-0.25_away          0.988913  ...          0.970930         -0.943636   \n",
      "spread_-0.25_home         -0.900528  ...         -0.845004          0.969746   \n",
      "spread_-0.5_away           0.991942  ...          0.976907         -0.942283   \n",
      "spread_-0.5_home          -0.907923  ...         -0.862218          0.965869   \n",
      "spread_-0.75_away          0.993587  ...          0.981680         -0.942871   \n",
      "spread_-0.75_home         -0.922258  ...         -0.878071          0.975781   \n",
      "spread_-1.0_away           1.000000  ...          0.989824         -0.947273   \n",
      "spread_-1.0_home          -0.950741  ...         -0.917381          0.989814   \n",
      "spread_-1.25_away          0.993863  ...          0.997819         -0.927109   \n",
      "spread_-1.25_home         -0.951084  ...         -0.916331          0.997520   \n",
      "spread_-1.5_away           0.989824  ...          1.000000         -0.914707   \n",
      "spread_-1.5_home          -0.947273  ...         -0.914707          1.000000   \n",
      "spread_-1.75_away          0.969350  ...          0.991747         -0.878459   \n",
      "spread_-1.75_home         -0.949314  ...         -0.917206          0.997086   \n",
      "spread_0.0_away            0.979548  ...          0.955846         -0.941778   \n",
      "spread_0.0_home           -0.878511  ...         -0.815096          0.952409   \n",
      "spread_0.25_away           0.972823  ...          0.949480         -0.928151   \n",
      "spread_0.25_home          -0.852904  ...         -0.784608          0.933425   \n",
      "totals_4.5_over            0.042498  ...         -0.026371         -0.073440   \n",
      "totals_4.5_under           0.281504  ...          0.337182         -0.229851   \n",
      "\n",
      "market             spread_-1.75_away  spread_-1.75_home  spread_0.0_away  \\\n",
      "market                                                                     \n",
      "money_line_away             0.900841          -0.926185         0.990212   \n",
      "money_line_draw             0.888270          -0.681772         0.728659   \n",
      "money_line_home            -0.820250           0.953211        -0.927893   \n",
      "spread_-0.25_away           0.947950          -0.941288         0.992284   \n",
      "spread_-0.25_home          -0.796782           0.962704        -0.935866   \n",
      "spread_-0.5_away            0.954737          -0.940423         0.987680   \n",
      "spread_-0.5_home           -0.828178           0.952718        -0.928319   \n",
      "spread_-0.75_away           0.959566          -0.943319         0.985894   \n",
      "spread_-0.75_home          -0.843250           0.964892        -0.937493   \n",
      "spread_-1.0_away            0.969350          -0.949314         0.979548   \n",
      "spread_-1.0_home           -0.886223           0.982595        -0.952578   \n",
      "spread_-1.25_away           0.987668          -0.928021         0.966897   \n",
      "spread_-1.25_home          -0.879803           0.994758        -0.949640   \n",
      "spread_-1.5_away            0.991747          -0.917206         0.955846   \n",
      "spread_-1.5_home           -0.878459           0.997086        -0.941778   \n",
      "spread_-1.75_away           1.000000          -0.876683         0.924513   \n",
      "spread_-1.75_home          -0.876683           1.000000        -0.942931   \n",
      "spread_0.0_away             0.924513          -0.942931         1.000000   \n",
      "spread_0.0_home            -0.757326           0.949938        -0.926278   \n",
      "spread_0.25_away            0.921020          -0.927932         0.995160   \n",
      "spread_0.25_home           -0.717282           0.936560        -0.909136   \n",
      "totals_4.5_over            -0.080895          -0.076378         0.149028   \n",
      "totals_4.5_under            0.364474          -0.241303         0.188108   \n",
      "\n",
      "market             spread_0.0_home  spread_0.25_away  spread_0.25_home  \\\n",
      "market                                                                   \n",
      "money_line_away          -0.920043          0.991884         -0.910065   \n",
      "money_line_draw          -0.522398          0.712339         -0.457628   \n",
      "money_line_home           0.967879         -0.920500          0.940308   \n",
      "spread_-0.25_away        -0.909078          0.990265         -0.881093   \n",
      "spread_-0.25_home         0.989413         -0.924535          0.974237   \n",
      "spread_-0.5_away         -0.896378          0.983438         -0.868170   \n",
      "spread_-0.5_home          0.964620         -0.920967          0.933469   \n",
      "spread_-0.75_away        -0.889801          0.980005         -0.863234   \n",
      "spread_-0.75_home         0.966474         -0.929178          0.937791   \n",
      "spread_-1.0_away         -0.878511          0.972823         -0.852904   \n",
      "spread_-1.0_home          0.956006         -0.943105          0.928048   \n",
      "spread_-1.25_away        -0.838714          0.961116         -0.808040   \n",
      "spread_-1.25_home         0.959336         -0.937528          0.939002   \n",
      "spread_-1.5_away         -0.815096          0.949480         -0.784608   \n",
      "spread_-1.5_home          0.952409         -0.928151          0.933425   \n",
      "spread_-1.75_away        -0.757326          0.921020         -0.717282   \n",
      "spread_-1.75_home         0.949938         -0.927932          0.936560   \n",
      "spread_0.0_away          -0.926278          0.995160         -0.909136   \n",
      "spread_0.0_home           1.000000         -0.921821          0.992915   \n",
      "spread_0.25_away         -0.921821          1.000000         -0.901333   \n",
      "spread_0.25_home          0.992915         -0.901333          1.000000   \n",
      "totals_4.5_over          -0.279188          0.188265         -0.299735   \n",
      "totals_4.5_under         -0.045914          0.160446         -0.038599   \n",
      "\n",
      "market             totals_4.5_over  totals_4.5_under  \n",
      "market                                                \n",
      "money_line_away           0.197777          0.171263  \n",
      "money_line_draw          -0.287524          0.417499  \n",
      "money_line_home          -0.178507         -0.097829  \n",
      "spread_-0.25_away         0.111964          0.211943  \n",
      "spread_-0.25_home        -0.204623         -0.085567  \n",
      "spread_-0.5_away          0.085434          0.230288  \n",
      "spread_-0.5_home         -0.155452         -0.112882  \n",
      "spread_-0.75_away         0.063231          0.260093  \n",
      "spread_-0.75_home        -0.143533         -0.134650  \n",
      "spread_-1.0_away          0.042498          0.281504  \n",
      "spread_-1.0_home         -0.105730         -0.182779  \n",
      "spread_-1.25_away        -0.003220          0.316115  \n",
      "spread_-1.25_home        -0.094725         -0.209618  \n",
      "spread_-1.5_away         -0.026371          0.337182  \n",
      "spread_-1.5_home         -0.073440         -0.229851  \n",
      "spread_-1.75_away        -0.080895          0.364474  \n",
      "spread_-1.75_home        -0.076378         -0.241303  \n",
      "spread_0.0_away           0.149028          0.188108  \n",
      "spread_0.0_home          -0.279188         -0.045914  \n",
      "spread_0.25_away          0.188265          0.160446  \n",
      "spread_0.25_home         -0.299735         -0.038599  \n",
      "totals_4.5_over           1.000000         -0.859774  \n",
      "totals_4.5_under         -0.859774          1.000000  \n",
      "\n",
      "[23 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "def compute_market_correlation(df: pd.DataFrame, value_col=\"implied_prob\"):\n",
    "    \"\"\"\n",
    "    Compute the correlation matrix of N betting markets based on\n",
    "    implied probabilities (or odds).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns ['timestamp', 'market', value_col]\n",
    "    value_col : str\n",
    "        Column name to compute correlation on (\"implied_prob\" or \"odds\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corr_matrix : pd.DataFrame\n",
    "        N×N correlation matrix of markets.\n",
    "    wide_df : pd.DataFrame\n",
    "        Time-indexed wide DataFrame used for correlation.\n",
    "    \"\"\"\n",
    "\n",
    "    wide_df = df.pivot_table(\n",
    "        index=\"timestamp\",\n",
    "        columns=\"market\",\n",
    "        values=value_col\n",
    "    )\n",
    "    cov = wide_df.corr()\n",
    "    return cov, wide_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cov, wide = compute_market_correlation(df)\n",
    "    print(\"\\n=== Correlation Matrix (20×20) ===\")\n",
    "    print(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8a7d2",
   "metadata": {},
   "source": [
    "## Penalty Coefficient Estimation\n",
    "\n",
    "Based on the method from Ying-Chang Lu et al. (2024), we estimate optimal penalty coefficients \n",
    "that balance constraint satisfaction with objective optimization. This ensures the QUBO formulation \n",
    "properly enforces constraints without dominating the objective function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e22fcc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating penalty coefficients...\n",
      "\n",
      "Estimated coefficients:\n",
      "  ALPHA (expected value weight): 10.0000 (was 1.0000)\n",
      "  BETA (risk/correlation penalty): 20.0000 (was 5.0000)\n",
      "\n",
      "Estimation details:\n",
      "  mu scale: 1.0000\n",
      "  cov scale: 0.8014\n",
      "  risk tolerance: 0.5000\n"
     ]
    }
   ],
   "source": [
    "def estimate_penalty_coefficients(mu, cov, A, risk_tolerance=0.5, min_alpha=0.1, max_alpha=10.0, min_beta=0.1, max_beta=20.0):\n",
    "    \"\"\"\n",
    "    Estimate optimal penalty coefficients (alpha, beta) for QUBO portfolio optimization.\n",
    "    \n",
    "    Based on the approach from: Ying-Chang Lu et al. \"Quantum-Inspired Portfolio Optimization \n",
    "    In The QUBO Framework\" (2024).\n",
    "    \n",
    "    The method balances:\n",
    "    - alpha: weight for expected value (linear term)\n",
    "    - beta: weight for risk/correlation penalty (quadratic term)\n",
    "    \n",
    "    Args:\n",
    "        mu: 1D numpy array of expected values\n",
    "        cov: 2D numpy array (NxN) covariance matrix\n",
    "        A: float, target allocation (max allocation size)\n",
    "        risk_tolerance: float in [0,1], higher = more risk tolerant (default 0.5)\n",
    "        min_alpha, max_alpha: bounds for alpha search\n",
    "        min_beta, max_beta: bounds for beta search\n",
    "    \n",
    "    Returns:\n",
    "        alpha: float, estimated optimal alpha coefficient\n",
    "        beta: float, estimated optimal beta coefficient\n",
    "        info: dict with estimation details\n",
    "    \"\"\"\n",
    "    N = len(mu)\n",
    "    \n",
    "    # Scale analysis: understand the magnitude of different terms\n",
    "    # Linear term scale: |alpha * mu_i + 2A|\n",
    "    mu_scale = np.abs(mu).mean()\n",
    "    linear_scale = max_alpha * mu_scale + 2 * A\n",
    "    \n",
    "    # Quadratic term scale: |beta * cov_ij + 1|\n",
    "    cov_scale = np.abs(cov.values).mean() if hasattr(cov, 'values') else np.abs(cov).mean()\n",
    "    quadratic_scale = max_beta * cov_scale + 1\n",
    "    \n",
    "    # Balance the scales so neither term dominates\n",
    "    # We want: linear_term ~ quadratic_term for typical portfolios\n",
    "    \n",
    "    # Estimate alpha: scale to make linear term comparable to quadratic term\n",
    "    # For a typical portfolio with ~A/2 bets selected:\n",
    "    # Linear contribution: ~(alpha * mu_mean + 2A) * (A/2)\n",
    "    # Quadratic contribution: ~(beta * cov_mean + 1) * (A/2)^2\n",
    "    # We want these to be balanced\n",
    "    \n",
    "    # Method 1: Scale-based estimation\n",
    "    # Target: alpha * mu_scale ~ beta * cov_scale (for balanced influence)\n",
    "    # Adjust based on risk tolerance\n",
    "    if cov_scale > 0:\n",
    "        # Higher risk_tolerance -> lower beta (less penalty on correlations)\n",
    "        beta_scale = (1 - risk_tolerance) * (linear_scale / cov_scale) if cov_scale > 0 else 1.0\n",
    "        alpha_scale = risk_tolerance * (quadratic_scale / mu_scale) if mu_scale > 0 else 1.0\n",
    "    else:\n",
    "        beta_scale = 1.0\n",
    "        alpha_scale = 1.0\n",
    "    \n",
    "    # Method 2: Constraint-based estimation\n",
    "    # Ensure allocation constraint is properly enforced\n",
    "    # The penalty term (A - sum(x))^2 should be significant relative to objective\n",
    "    allocation_penalty_scale = A ** 2\n",
    "    \n",
    "    # Estimate beta to ensure correlation penalties are meaningful\n",
    "    # Typical correlation penalty: beta * sum(cov_ij) for correlated bets\n",
    "    avg_correlation = np.abs(cov.values).mean() if hasattr(cov, 'values') else np.abs(cov).mean()\n",
    "    \n",
    "    if avg_correlation > 0:\n",
    "        # Beta should be large enough that correlation penalties matter\n",
    "        # but not so large that they dominate\n",
    "        beta_constraint = allocation_penalty_scale / (avg_correlation * A * (A - 1) / 2) if A > 1 else 1.0\n",
    "    else:\n",
    "        beta_constraint = 1.0\n",
    "    \n",
    "    # Combine methods with risk tolerance weighting\n",
    "    alpha = min_alpha + (max_alpha - min_alpha) * alpha_scale * risk_tolerance\n",
    "    beta = min_beta + (max_beta - min_beta) * (beta_scale * (1 - risk_tolerance) + beta_constraint * risk_tolerance) / 2\n",
    "    \n",
    "    # Clamp to bounds\n",
    "    alpha = np.clip(alpha, min_alpha, max_alpha)\n",
    "    beta = np.clip(beta, min_beta, max_beta)\n",
    "    \n",
    "    # Additional refinement: ensure constraint satisfaction\n",
    "    # Test that typical constraint violations would be penalized enough\n",
    "    # If we exceed allocation by 1, penalty should be significant\n",
    "    constraint_violation_penalty = (A + 1 - A) ** 2  # = 1\n",
    "    typical_objective = np.abs(mu).mean() * A / 2\n",
    "    \n",
    "    # Ensure beta is large enough that constraint violations are meaningful\n",
    "    if typical_objective > 0:\n",
    "        min_beta_effective = constraint_violation_penalty / (avg_correlation * A) if avg_correlation > 0 else min_beta\n",
    "        beta = max(beta, min_beta_effective * 0.5)  # Safety factor\n",
    "    \n",
    "    info = {\n",
    "        'mu_scale': mu_scale,\n",
    "        'cov_scale': cov_scale,\n",
    "        'linear_scale': linear_scale,\n",
    "        'quadratic_scale': quadratic_scale,\n",
    "        'risk_tolerance': risk_tolerance,\n",
    "        'alpha_scale': alpha_scale,\n",
    "        'beta_scale': beta_scale,\n",
    "        'beta_constraint': beta_constraint\n",
    "    }\n",
    "    \n",
    "    return alpha, beta, info\n",
    "\n",
    "# Estimate penalty coefficients\n",
    "# NOTE: This should be run AFTER mu and cov are computed\n",
    "print(\"Estimating penalty coefficients...\")\n",
    "if 'mu' not in globals() or 'cov' not in globals():\n",
    "    raise ValueError(\"mu and cov must be computed before penalty coefficient estimation\")\n",
    "    \n",
    "ALPHA_EST, BETA_EST, est_info = estimate_penalty_coefficients(mu, cov, A, risk_tolerance=0.5)\n",
    "\n",
    "print(f\"\\nEstimated coefficients:\")\n",
    "print(f\"  ALPHA (expected value weight): {ALPHA_EST:.4f} (was {ALPHA:.4f})\")\n",
    "print(f\"  BETA (risk/correlation penalty): {BETA_EST:.4f} (was {BETA:.4f})\")\n",
    "print(f\"\\nEstimation details:\")\n",
    "print(f\"  mu scale: {est_info['mu_scale']:.4f}\")\n",
    "print(f\"  cov scale: {est_info['cov_scale']:.4f}\")\n",
    "print(f\"  risk tolerance: {est_info['risk_tolerance']:.4f}\")\n",
    "\n",
    "# Use estimated values\n",
    "ALPHA = ALPHA_EST\n",
    "BETA = BETA_EST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f74e2fde-539a-43a6-b5e7-1503ba542fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>odds</th>\n",
       "      <th>implied_prob</th>\n",
       "      <th>expected_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spread_-0.75_away</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>2.030</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-1.25_away</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>1.595</td>\n",
       "      <td>0.626959</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-1.0_home</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-0.75_home</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>1.884</td>\n",
       "      <td>0.530786</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-0.5_home</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>1.694</td>\n",
       "      <td>0.590319</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-1.25_home</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>2.450</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals_4.5_over</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>3.330</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-1.5_away</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>1.487</td>\n",
       "      <td>0.672495</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-0.25_home</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>1.512</td>\n",
       "      <td>0.661376</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-1.5_home</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>2.750</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-0.25_away</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>2.700</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-1.0_away</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>1.757</td>\n",
       "      <td>0.569152</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-1.75_away</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>1.357</td>\n",
       "      <td>0.736920</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_0.0_home</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.753012</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-1.75_home</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>3.290</td>\n",
       "      <td>0.303951</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_0.0_away</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>3.530</td>\n",
       "      <td>0.283286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money_line_away</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>4.470</td>\n",
       "      <td>0.223714</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_0.25_home</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>1.269</td>\n",
       "      <td>0.788022</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money_line_draw</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>4.460</td>\n",
       "      <td>0.224215</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_0.25_away</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>3.950</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money_line_home</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>1.689</td>\n",
       "      <td>0.592066</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_-0.5_away</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals_4.5_under</th>\n",
       "      <td>2025-12-02 14:59:30</td>\n",
       "      <td>1.346</td>\n",
       "      <td>0.742942</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            timestamp   odds  implied_prob  expected_value\n",
       "market                                                                    \n",
       "spread_-0.75_away 2025-12-02 14:59:30  2.030      0.492611             1.0\n",
       "spread_-1.25_away 2025-12-02 14:59:30  1.595      0.626959             1.0\n",
       "spread_-1.0_home  2025-12-02 14:59:30  2.150      0.465116             1.0\n",
       "spread_-0.75_home 2025-12-02 14:59:30  1.884      0.530786             1.0\n",
       "spread_-0.5_home  2025-12-02 14:59:30  1.694      0.590319             1.0\n",
       "spread_-1.25_home 2025-12-02 14:59:30  2.450      0.408163             1.0\n",
       "totals_4.5_over   2025-12-02 14:59:30  3.330      0.300300             1.0\n",
       "spread_-1.5_away  2025-12-02 14:59:30  1.487      0.672495             1.0\n",
       "spread_-0.25_home 2025-12-02 14:59:30  1.512      0.661376             1.0\n",
       "spread_-1.5_home  2025-12-02 14:59:30  2.750      0.363636             1.0\n",
       "spread_-0.25_away 2025-12-02 14:59:30  2.700      0.370370             1.0\n",
       "spread_-1.0_away  2025-12-02 14:59:30  1.757      0.569152             1.0\n",
       "spread_-1.75_away 2025-12-02 14:59:30  1.357      0.736920             1.0\n",
       "spread_0.0_home   2025-12-02 14:59:30  1.328      0.753012             1.0\n",
       "spread_-1.75_home 2025-12-02 14:59:30  3.290      0.303951             1.0\n",
       "spread_0.0_away   2025-12-02 14:59:30  3.530      0.283286             1.0\n",
       "money_line_away   2025-12-02 14:59:30  4.470      0.223714             1.0\n",
       "spread_0.25_home  2025-12-02 14:59:30  1.269      0.788022             1.0\n",
       "money_line_draw   2025-12-02 14:59:30  4.460      0.224215             1.0\n",
       "spread_0.25_away  2025-12-02 14:59:30  3.950      0.253165             1.0\n",
       "money_line_home   2025-12-02 14:59:30  1.689      0.592066             1.0\n",
       "spread_-0.5_away  2025-12-02 14:59:30  2.250      0.444444             1.0\n",
       "totals_4.5_under  2025-12-02 14:59:30  1.346      0.742942             1.0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the lastest odds from the API\n",
    "final_snapshot = (\n",
    "    df.sort_values(\"timestamp\")\n",
    "      .groupby(\"market\")\n",
    "      .tail(1)\n",
    "      .set_index(\"market\")\n",
    ")\n",
    "final_snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d3240302-3fb2-4764-9da6-6c1a63338ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_final = final_snapshot[\"implied_prob\"].values\n",
    "odds_final = final_snapshot[\"odds\"].values\n",
    "\n",
    "# Expected value per market\n",
    "mu = p_final * odds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "04770e81-5f0a-4d14-98cd-51f33c2ebd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    x          E  num_bets\n",
      "0   (0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, ... -62.018248        10\n",
      "1   (0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, ... -61.841442        10\n",
      "2   (0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, ... -61.803726        10\n",
      "3   (0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, ... -61.677737        10\n",
      "4   (0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, ... -61.492248        10\n",
      "5   (0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, ... -61.067316        10\n",
      "6   (0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, ... -61.036344        10\n",
      "7   (0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, ... -60.967496        10\n",
      "8   (0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, ... -60.936915        10\n",
      "9   (0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, ... -60.749097        10\n",
      "10  (0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, ... -60.713099        10\n",
      "11  (0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, ... -60.709861        10\n",
      "12  (0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, ... -60.693841        10\n",
      "13  (0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, ... -60.688040        10\n",
      "14  (0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, ... -60.603909        10\n",
      "15  (0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, ... -60.510031        10\n",
      "16  (0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, ... -60.506988        10\n",
      "17  (0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, ... -60.441174        10\n",
      "18  (0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, ... -60.413502        10\n",
      "19  (0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, ... -60.298472        10\n",
      "20  (0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, ... -60.270501        10\n",
      "21  (0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, ... -60.215041        10\n",
      "22  (0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, ... -60.168970        10\n",
      "23  (0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, ... -60.166294        10\n",
      "24  (0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, ... -60.158290        10\n",
      "25  (0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, ... -60.122460        10\n",
      "26  (0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, ... -60.112333        10\n",
      "27  (0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, ... -60.107660        10\n",
      "28  (0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, ... -60.105667        10\n",
      "29  (0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, ... -60.099206        10\n",
      "30  (0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, ... -60.066233        10\n",
      "31  (0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, ... -60.050994        10\n",
      "\n",
      "Checked 8388608 Configurations for N=23.\n",
      "Brute Force - Time to Ground State: 84.5700 seconds\n"
     ]
    }
   ],
   "source": [
    "#Brute-Force Calculations\n",
    "N = len(final_snapshot)\n",
    "all_results = []\n",
    "\n",
    "start_time = time.perf_counter() \n",
    "\n",
    "for bits in itertools.product([0, 1], repeat=N):\n",
    "    x = np.array(bits)\n",
    "    E = portfolio_energy_qubo(x, mu, cov.values, alpha=ALPHA, beta=BETA, A=A)\n",
    "    all_results.append({\n",
    "        \"x\": bits,\n",
    "        \"E\": E,\n",
    "        \"num_bets\": x.sum()\n",
    "    })\n",
    "\n",
    "end_time = time.perf_counter() \n",
    "elapsed_bf = end_time - start_time\n",
    "\n",
    "results_df = (\n",
    "    pd.DataFrame(all_results)\n",
    "      .sort_values(\"E\", ascending=True)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(results_df.head(32))\n",
    "print(f\"\\nChecked {2**N} Configurations for N={N}.\")\n",
    "print(f\"Brute Force - Time to Ground State: {elapsed_bf:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4eadbc",
   "metadata": {},
   "source": [
    "## QUBO → Ising mapping and interpretation of scaling factors\n",
    "\n",
    "The ORBIT simulator expects an **Ising model** of the form\n",
    "$$E_{\\text{Ising}}(s) = \\sum_i h_i s_i + \\sum_{i<j} J_{ij} s_i s_j$$\n",
    "where each spin variable $s_i \\{-1, +1\\}$.\n",
    "\n",
    "Our QUBO is defined in terms of binary variables $x_i \\in {0,1}$:\n",
    "$$\n",
    "E_{\\text{QUBO}}(x) = = - \\sum\\limits_{i}(\\alpha \\mu_{i} + 2A)x_{i} + \\sum\\limits_{i,j}(\\beta \\Sigma_{i, j} + 1)x_{i}x_{J} + A^{2}\n",
    "$$\n",
    "\n",
    "Note\n",
    "$$\n",
    "\\sum_{i,j} (\\beta \\Sigma_{ij} + 1)x_i x_j = \\sum_i (\\beta \\Sigma_{ii} + 1)x_i^2 + \\sum_{i<j} 2(\\beta \\Sigma_{ij} + 1)x_i x_j\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "$$\n",
    "E_{\\text{QUBO}}(x) = \\sum_i a_i x_i + \\sum_{i<j} b_{ij} x_i x_j + \\text{const} \\\\\n",
    "a_i = -(\\alpha \\mu_i + 2A) + (\\beta \\Sigma_{ii} + 1) \\\\\n",
    "b_{ij} = 2(\\beta \\Sigma_{ij} + 1), \\quad i<j\n",
    "$$\n",
    "\n",
    "The standard mapping between these two formulations uses\n",
    "$$x_i = \\frac{1 + s_i}{2}$$\n",
    "\n",
    "If we substitute $x_i = (1+s_i)/2$ into the QUBO and collect terms, we obtain an Ising model with:\n",
    "\n",
    "- couplings\n",
    "  $$J_{ij} = \\frac{b_{ij}}{4}$$\n",
    "- local fields\n",
    "  $$h_i = \\frac{a_i}{2} + \\frac{1}{4}\\sum_{j \\neq i} b_{ij}$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\n",
    "J_{ij} = \\frac{1}{4} b_{ij} = \\frac{1}{4}\\, 2(\\beta \\Sigma_{ij} + 1) = \\frac{1}{2}(\\beta \\Sigma_{ij} + 1), \\quad i<j \\\\\n",
    "J_{ij} = \\frac{1}{2}(\\beta \\Sigma_{ij} + 1),\\quad i<j\n",
    "$$\n",
    "\n",
    "and,\n",
    "$$\n",
    "a_i = -(\\alpha \\mu_i + 2A) + (\\beta \\Sigma_{ii} + 1) = -\\alpha \\mu_i - 2A + \\beta \\Sigma_{ii} + 1 \\\\\n",
    "\\sum_{j\\neq i} b_{ij} = \\sum_{j\\neq i} 2(\\beta \\Sigma_{ij} + 1) = 2\\sum_{j\\neq i} (\\beta \\Sigma_{ij} + 1) \\\\\n",
    "$$\n",
    "\n",
    "giving,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "h_i\n",
    "&= \\frac{a_i}{2} + \\frac{1}{4}\\sum_{j\\neq i} b_{ij} \\\\\n",
    "&= \\frac{1}{2}(-\\alpha \\mu_i - 2A + \\beta \\Sigma_{ii} + 1) + \\frac{1}{4}\\cdot 2\\sum_{j\\neq i} (\\beta \\Sigma_{ij} + 1) \\\\\n",
    "&= -\\frac{\\alpha}{2}\\mu_i - A + \\frac{1}{2}(\\beta \\Sigma_{ii} + 1) + \\frac{1}{2}\\sum_{j\\neq i} (\\beta \\Sigma_{ij} + 1).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Two important points for interpretation:\n",
    "\n",
    "1. **Absolute energies differ, minimisers do not**  \n",
    "   The Ising energy and the original QUBO energy can have different absolute values because of constant shifts and rescaling. What matters is that they share the **same minimising configuration**.\n",
    "\n",
    "2. **Validation via brute force**  \n",
    "   For the small problem size in this notebook, we perform an exhaustive search over all $2^N$ portfolios to find the exact ground state of the QUBO.  \n",
    "   We then run ORBIT on the corresponding Ising instance and **compare ORBIT’s solution to the brute-force optimum**, confirming that the mapping and implementation are consistent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4eda03",
   "metadata": {},
   "source": [
    "## Two-Stage Search Preprocessing\n",
    "\n",
    "Based on the method from Ying-Chang Lu et al. (2024), we implement a two-stage approach:\n",
    "- **Stage 1 (Preprocessing)**: Quickly filters and reduces the problem space by identifying \n",
    "  promising candidates and eliminating poor options\n",
    "- **Stage 2 (Optimization)**: Applies the main optimizers (ORBIT, SA, Greedy) to the \n",
    "  preprocessed problem for faster and better solutions\n",
    "\n",
    "This preprocessing step is applied once and benefits all optimization methods, ensuring \n",
    "fair comparison while improving efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ca671a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying two-stage preprocessing...\n",
      "\n",
      "Preprocessing results:\n",
      "  Original problem size: 23\n",
      "  Active bets after filtering: 23\n",
      "  Filtered out: 0\n",
      "  High correlation pairs found: 193\n",
      "  Initial solution bets: 10\n",
      "  EV threshold: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def two_stage_preprocessing(mu, cov, alpha, beta, A, ev_threshold_percentile=10, correlation_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Two-stage preprocessing for QUBO portfolio optimization.\n",
    "    \n",
    "    Based on: Ying-Chang Lu et al. \"Quantum-Inspired Portfolio Optimization \n",
    "    In The QUBO Framework\" (2024).\n",
    "    \n",
    "    Stage 1: Preprocessing\n",
    "    - Filters out bets with very low expected value\n",
    "    - Identifies highly correlated bets that should be mutually exclusive\n",
    "    - Creates a reduced problem space or initial solution\n",
    "    \n",
    "    Stage 2: Returns preprocessed problem ready for optimization\n",
    "    \n",
    "    Args:\n",
    "        mu: 1D numpy array of expected values\n",
    "        cov: 2D numpy array (NxN) covariance matrix\n",
    "        alpha: float, penalty coefficient for linear term\n",
    "        beta: float, penalty coefficient for quadratic term\n",
    "        A: float, target allocation\n",
    "        ev_threshold_percentile: int, percentile threshold for filtering low EV bets (default 10)\n",
    "        correlation_threshold: float, correlation threshold for identifying redundant bets (default 0.8)\n",
    "    \n",
    "    Returns:\n",
    "        preprocessed_mu: filtered/reduced mu array\n",
    "        preprocessed_cov: filtered/reduced cov matrix\n",
    "        active_indices: array of indices that remain after preprocessing\n",
    "        initial_solution: optional initial solution (can be None)\n",
    "        preprocessing_info: dict with preprocessing statistics\n",
    "    \"\"\"\n",
    "    N = len(mu)\n",
    "    cov_matrix = cov.values if hasattr(cov, 'values') else cov\n",
    "    \n",
    "    # Stage 1: Preprocessing\n",
    "    \n",
    "    # Step 1.1: Filter by expected value\n",
    "    # Remove bets with very low expected value (bottom percentile)\n",
    "    ev_threshold = np.percentile(mu, ev_threshold_percentile)\n",
    "    high_ev_mask = mu >= ev_threshold\n",
    "    \n",
    "    # Step 1.2: Identify highly correlated pairs\n",
    "    # For highly correlated bets (correlation > threshold), we might want to\n",
    "    # prefer the one with higher EV\n",
    "    high_correlation_pairs = []\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "            if abs(cov_matrix[i, j]) > correlation_threshold:\n",
    "                high_correlation_pairs.append((i, j, cov_matrix[i, j]))\n",
    "    \n",
    "    # Step 1.3: Create active set\n",
    "    # Start with high EV bets\n",
    "    active_indices = np.where(high_ev_mask)[0].tolist()\n",
    "    \n",
    "    # For highly correlated pairs, prefer the one with higher EV\n",
    "    # (This is a heuristic - in practice, the optimizer will decide)\n",
    "    excluded_from_correlation = set()\n",
    "    for i, j, corr in high_correlation_pairs:\n",
    "        if i in excluded_from_correlation or j in excluded_from_correlation:\n",
    "            continue\n",
    "        # If both are in active set and highly correlated, we could remove one\n",
    "        # But let's keep both and let the optimizer decide (correlation penalty will handle it)\n",
    "        pass\n",
    "    \n",
    "    # Step 1.4: Additional filtering - remove bets that are dominated\n",
    "    # A bet is dominated if there's another bet with:\n",
    "    # - Higher or equal EV\n",
    "    # - Lower or equal correlation with all other bets\n",
    "    # This is conservative - we'll keep most bets and let optimization decide\n",
    "    \n",
    "    # For now, we'll keep all high-EV bets\n",
    "    # The correlation penalties in the QUBO will naturally discourage\n",
    "    # selecting highly correlated bets together\n",
    "    \n",
    "    active_indices = np.array(sorted(set(active_indices)))\n",
    "    \n",
    "    # Step 1.5: Create initial solution (optional)\n",
    "    # Greedy initialization: select top A bets by EV, avoiding highly correlated ones\n",
    "    initial_solution = np.zeros(N, dtype=int)\n",
    "    selected = []\n",
    "    remaining = active_indices.tolist()\n",
    "    \n",
    "    # Sort by EV (descending)\n",
    "    remaining_sorted = sorted(remaining, key=lambda idx: mu[idx], reverse=True)\n",
    "    \n",
    "    for idx in remaining_sorted:\n",
    "        if len(selected) >= A:\n",
    "            break\n",
    "        \n",
    "        # Check if this bet is too correlated with already selected bets\n",
    "        too_correlated = False\n",
    "        for sel_idx in selected:\n",
    "            if abs(cov_matrix[idx, sel_idx]) > correlation_threshold:\n",
    "                too_correlated = True\n",
    "                break\n",
    "        \n",
    "        if not too_correlated:\n",
    "            initial_solution[idx] = 1\n",
    "            selected.append(idx)\n",
    "    \n",
    "    # If we haven't filled A slots, fill with remaining high-EV bets\n",
    "    for idx in remaining_sorted:\n",
    "        if len(selected) >= A:\n",
    "            break\n",
    "        if idx not in selected:\n",
    "            initial_solution[idx] = 1\n",
    "            selected.append(idx)\n",
    "    \n",
    "    # Create preprocessed problem\n",
    "    # Option 1: Use full problem but with initial solution\n",
    "    # Option 2: Use reduced problem (only active indices)\n",
    "    # We'll go with Option 1 for now (use full problem, provide initial solution)\n",
    "    # This allows all optimizers to work on the same problem\n",
    "    \n",
    "    preprocessed_mu = mu  # Keep full mu\n",
    "    preprocessed_cov = cov  # Keep full cov\n",
    "    \n",
    "    preprocessing_info = {\n",
    "        'original_size': N,\n",
    "        'active_size': len(active_indices),\n",
    "        'filtered_out': N - len(active_indices),\n",
    "        'high_ev_threshold': ev_threshold,\n",
    "        'high_correlation_pairs_count': len(high_correlation_pairs),\n",
    "        'initial_solution_bets': int(initial_solution.sum()),\n",
    "        'active_indices': active_indices\n",
    "    }\n",
    "    \n",
    "    return preprocessed_mu, preprocessed_cov, active_indices, initial_solution, preprocessing_info\n",
    "\n",
    "# Apply two-stage preprocessing\n",
    "print(\"Applying two-stage preprocessing...\")\n",
    "preprocessed_mu, preprocessed_cov, active_indices, initial_solution, prep_info = two_stage_preprocessing(\n",
    "    mu, cov, ALPHA, BETA, A, \n",
    "    ev_threshold_percentile=10, \n",
    "    correlation_threshold=0.8\n",
    ")\n",
    "\n",
    "print(f\"\\nPreprocessing results:\")\n",
    "print(f\"  Original problem size: {prep_info['original_size']}\")\n",
    "print(f\"  Active bets after filtering: {prep_info['active_size']}\")\n",
    "print(f\"  Filtered out: {prep_info['filtered_out']}\")\n",
    "print(f\"  High correlation pairs found: {prep_info['high_correlation_pairs_count']}\")\n",
    "print(f\"  Initial solution bets: {prep_info['initial_solution_bets']}\")\n",
    "print(f\"  EV threshold: {prep_info['high_ev_threshold']:.4f}\")\n",
    "\n",
    "# Store for use in optimizers\n",
    "INITIAL_SOLUTION = initial_solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e0e17311-a1a8-4fb2-aa06-9440c7c78a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Ising parameters too large (max=23.21). Scaling by 0.3447\n",
      "  After scaling: max_J=3.62, max_h=8.00\n",
      "[2025-12-07 07:40:05] INFO - orbit.simulator: Simulation starting...\n",
      "[2025-12-07 07:45:52] INFO - orbit.simulator: Simulation completed in 332.36 seconds\n",
      "=== ORBIT optimisation result ===\n",
      "Time to (approximately) find ground state: 490.9399 seconds\n",
      "\n",
      "Spins (s*): [1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
      "Bits  (x*): [1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
      "Number of bets in portfolio: 10\n",
      "Selected bets: ['spread_-0.75_away', 'spread_-0.75_home', 'spread_-0.5_home', 'spread_-1.25_home', 'spread_-0.25_away', 'spread_-1.75_away', 'money_line_away', 'spread_0.25_home', 'spread_-0.5_away', 'totals_4.5_under']\n",
      "\n",
      "ORBIT reported min_cost: -1.6565673668487513\n",
      "Objective E = portfolio_energy_qubo(x*, w, Q): -57.08786369104206\n",
      "\n",
      "=== Comparison with brute force ===\n",
      "Brute-force best E: -62.018247989643385\n",
      "Brute-force best x: (0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Orbit Calculations\n",
    "N = len(final_snapshot)\n",
    "bets = final_snapshot.index.tolist()  \n",
    "\n",
    "# Standard QUBO -> Ising mapping \n",
    "J0 = 0.5 * (BETA * cov.values + 1.0)\n",
    "h0 = - 0.5 * ALPHA * mu - A + np.sum(J0, axis=1)\n",
    "\n",
    "# Normalize Ising parameters to prevent numerical overflow in ORBIT\n",
    "# ORBIT works best when parameters are in a reasonable range (typically [-10, 10])\n",
    "max_J = np.abs(J0).max()\n",
    "max_h = np.abs(h0).max()\n",
    "max_param = max(max_J, max_h)\n",
    "\n",
    "# If parameters are too large, scale them down\n",
    "# Target range: keep max parameter around 5-10 for stability\n",
    "target_max = 8.0\n",
    "if max_param > target_max:\n",
    "    scale_factor = target_max / max_param\n",
    "    print(f\"Warning: Ising parameters too large (max={max_param:.2f}). Scaling by {scale_factor:.4f}\")\n",
    "    J0 = J0 * scale_factor\n",
    "    h0 = h0 * scale_factor\n",
    "    print(f\"  After scaling: max_J={np.abs(J0).max():.2f}, max_h={np.abs(h0).max():.2f}\")\n",
    "else:\n",
    "    scale_factor = 1.0\n",
    "    print(f\"Ising parameter magnitudes: max_J={max_J:.2f}, max_h={max_h:.2f} (OK)\")\n",
    "\n",
    "ising_J = J0\n",
    "ising_h = h0\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "result = orbit.optimize_ising(\n",
    "    ising_J,\n",
    "    ising_h,\n",
    "    n_replicas=10,\n",
    "    full_sweeps=100_000,\n",
    "    beta_initial=0.35,\n",
    "    beta_end=3.5,\n",
    "    beta_step_interval=1,\n",
    ")\n",
    "\n",
    "elapsed_orb = time.perf_counter() - start_time\n",
    "\n",
    "s_star = np.array(result.min_state)  \n",
    "x_star = (1 + s_star) // 2                 \n",
    "\n",
    "E_orbit = portfolio_energy_qubo(x_star, mu, cov, alpha=ALPHA, beta=BETA, A=A)\n",
    "\n",
    "chosen_bets = [b for b, bit in zip(bets, x_star) if bit == 1]\n",
    "\n",
    "print(\"=== ORBIT optimisation result ===\")\n",
    "print(f\"Time to (approximately) find ground state: {elapsed_orb:.4f} seconds\\n\")\n",
    "\n",
    "print(\"Spins (s*):\", s_star.tolist())\n",
    "print(\"Bits  (x*):\", x_star.tolist())\n",
    "print(\"Number of bets in portfolio:\", int(x_star.sum()))\n",
    "print(\"Selected bets:\", chosen_bets)\n",
    "\n",
    "print(\"\\nORBIT reported min_cost:\", result.min_cost)\n",
    "print(\"Objective E = portfolio_energy_qubo(x*, w, Q):\", E_orbit)\n",
    "\n",
    "# Optional: compare with brute-force ground state if you still have results_df\n",
    "if 'results_df' in globals():\n",
    "    print(\"\\n=== Comparison with brute force ===\")\n",
    "    print(\"Brute-force best E:\", results_df.loc[0, 'E'])\n",
    "    print(\"Brute-force best x:\", results_df.loc[0, 'x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5c9393ba-bc61-4dd7-81ef-23e136064d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ORBIT vs Brute Force ===\n",
      "ORBIT bitstring: (1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1)\n",
      "ORBIT energy from brute-force table: -57.087864\n",
      "Ground state energy (brute force):   -62.018248\n",
      "Ground state bitstring:              (0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1)\n",
      "\n",
      "Rank of ORBIT state among all 2^23 configs: 591 (1 = ground state)\n",
      "Energy gap to ground state: 4.930384\n",
      "\n",
      "Time to the lowest state using orbit: 490.9399 seconds\n",
      "\n",
      "Time to find the ground state using brute-force  : 84.5700 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Check ORBIT solution against brute-force results and rank it ---\n",
    "orbit_bits = tuple(int(b) for b in x_star)\n",
    "matches = results_df[results_df[\"x\"] == orbit_bits]\n",
    "\n",
    "if matches.empty:\n",
    "    print(\"⚠ ORBIT bitstring not found in brute-force results (this should not happen if N matches).\")\n",
    "else:\n",
    "    match_idx = matches.index[0]   # 0-based index in results_df\n",
    "    rank = match_idx + 1           # human-friendly rank (1 = best)\n",
    "\n",
    "    E_best = results_df.loc[0, \"E\"]\n",
    "    x_best = results_df.loc[0, \"x\"]\n",
    "    E_orbit_bruteforce = matches.iloc[0][\"E\"]\n",
    "\n",
    "    print(\"\\n=== ORBIT vs Brute Force ===\")\n",
    "    print(f\"ORBIT bitstring: {orbit_bits}\")\n",
    "    print(f\"ORBIT energy from brute-force table: {E_orbit_bruteforce:.6f}\")\n",
    "    print(f\"Ground state energy (brute force):   {E_best:.6f}\")\n",
    "    print(f\"Ground state bitstring:              {x_best}\")\n",
    "\n",
    "    print(f\"\\nRank of ORBIT state among all 2^{N} configs: {rank} (1 = ground state)\")\n",
    "    print(f\"Energy gap to ground state: {E_orbit_bruteforce - E_best:.6f}\")\n",
    "\n",
    "    # Optional: how many configs are strictly better / equal\n",
    "    n_better = (results_df[\"E\"] < E_orbit_bruteforce).sum()\n",
    "    n_equal  = (results_df[\"E\"] == E_orbit_bruteforce).sum()\n",
    "    print(\"\")\n",
    "    print(f\"Time to the lowest state using orbit: {elapsed_orb:.4f} seconds\\n\")\n",
    "    print(f\"Time to find the ground state using brute-force  : {elapsed_bf:.4f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ea36ce83-af28-49b9-a453-759a5db0dbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simulated Annealing result ===\n",
      "Bits (x*): [0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
      "Number of bets in portfolio: 10\n",
      "SA energy: -61.492248\n",
      "Time to (approximately) find ground state: 9.4245 seconds\n",
      "\n",
      "=== SA vs Brute Force ===\n",
      "Rank of SA state among all 2^N configs: 5 (1 = ground state)\n",
      "Ground state energy (brute force): -62.018248\n",
      "Energy gap to ground state: 0.526000\n"
     ]
    }
   ],
   "source": [
    "def sa_optimize_qubo(w, cov, n_steps=100_000, T_start=5.0, T_end=0.01, seed=123):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = len(w)\n",
    "\n",
    "    def energy(x):\n",
    "        return portfolio_energy_qubo(x, w, cov, alpha=ALPHA, beta=BETA, A=A)  # same sign convention as brute-force\n",
    "\n",
    "    x = rng.integers(0, 2, size=N, dtype=int)\n",
    "    E = energy(x)\n",
    "\n",
    "    best_x = x.copy()\n",
    "    best_E = E\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        T = T_start * (T_end / T_start) ** (step / max(1, n_steps - 1))\n",
    "\n",
    "        i = rng.integers(0, N)\n",
    "        x_new = x.copy()\n",
    "        x_new[i] = 1 - x_new[i]\n",
    "\n",
    "        E_new = energy(x_new)\n",
    "        dE = E_new - E\n",
    "\n",
    "        if dE <= 0 or rng.random() < np.exp(-dE / T):\n",
    "            x, E = x_new, E_new\n",
    "            if E < best_E:\n",
    "                best_E = E\n",
    "                best_x = x.copy()\n",
    "\n",
    "    return best_x, best_E\n",
    "\n",
    "start = time.perf_counter()\n",
    "x_sa, E_sa = sa_optimize_qubo(mu, cov, n_steps=100_000)\n",
    "elapsed_sa = time.perf_counter() - start\n",
    "\n",
    "print(\"=== Simulated Annealing result ===\")\n",
    "print(\"Bits (x*):\", x_sa.tolist())\n",
    "print(\"Number of bets in portfolio:\", int(x_sa.sum()))\n",
    "print(f\"SA energy: {E_sa:.6f}\")\n",
    "print(f\"Time to (approximately) find ground state: {elapsed_sa:.4f} seconds\")\n",
    "\n",
    "if \"results_df\" in globals():\n",
    "    sa_bits = tuple(int(b) for b in x_sa)\n",
    "    matches = results_df[results_df[\"x\"] == sa_bits]\n",
    "\n",
    "    if matches.empty:\n",
    "        print(\"\\nSA bitstring not found in brute-force table.\")\n",
    "    else:\n",
    "        idx = matches.index[0]\n",
    "        rank = idx + 1\n",
    "        E_best = results_df.loc[0, \"E\"]\n",
    "        print(\"\\n=== SA vs Brute Force ===\")\n",
    "        print(f\"Rank of SA state among all 2^N configs: {rank} (1 = ground state)\")\n",
    "        print(f\"Ground state energy (brute force): {E_best:.6f}\")\n",
    "        print(f\"Energy gap to ground state: {E_sa - E_best:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "360f1fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Greedy Algorithm result ===\n",
      "Bits (x*): [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1]\n",
      "Number of bets in portfolio: 10\n",
      "Greedy energy: -58.709100\n",
      "Time to find local optimum: 0.0050 seconds\n",
      "\n",
      "=== Greedy vs Brute Force ===\n",
      "Rank of Greedy state among all 2^N configs: 162 (1 = ground state)\n",
      "Ground state energy (brute force): -62.018248\n",
      "Energy gap to ground state: 3.309148\n",
      "\n",
      "=== Greedy vs Simulated Annealing ===\n",
      "SA energy: -61.492248\n",
      "Greedy energy: -58.709100\n",
      "Energy difference (Greedy - SA): 2.783148\n",
      "SA time: 9.4245 seconds\n",
      "Greedy time: 0.0050 seconds\n",
      "Speedup: 1872.24x\n",
      "Solutions differ in 4 bits\n"
     ]
    }
   ],
   "source": [
    "# Greedy Optimisation Algorithm\n",
    "# Based on: Andrew Vince. A framework for the greedy algorithm.\n",
    "# Discrete Applied Mathematics, 121(1-3):247–260, 2002.\n",
    "\n",
    "def greedy_optimize_qubo(mu, cov, alpha=ALPHA, beta=BETA, A=A):\n",
    "    \"\"\"\n",
    "    Greedy algorithm for QUBO optimization following Vince (2002) framework.\n",
    "    \n",
    "    The algorithm starts with an empty solution and iteratively adds/removes\n",
    "    variables (bits) that give the best local improvement in energy.\n",
    "    \n",
    "    Args:\n",
    "        mu: 1D numpy array of expected values (linear coefficients)\n",
    "        cov: 2D numpy array (NxN) covariance matrix (quadratic coefficients)\n",
    "        alpha: float, weight for linear term\n",
    "        beta: float, weight for quadratic penalty\n",
    "        A: float, target allocation (max allocation size)\n",
    "    \n",
    "    Returns:\n",
    "        x: 1D numpy array of 0/1 solution\n",
    "        E: float, final energy value\n",
    "    \"\"\"\n",
    "    N = len(mu)\n",
    "    \n",
    "    def energy(x):\n",
    "        \"\"\"Compute QUBO energy for given bitstring x.\"\"\"\n",
    "        return portfolio_energy_qubo(x, mu, cov, alpha=alpha, beta=beta, A=A)\n",
    "    \n",
    "    # Initialize: start with all zeros (empty portfolio)\n",
    "    x = np.zeros(N, dtype=int)\n",
    "    E = energy(x)\n",
    "    \n",
    "    improved = True\n",
    "    iterations = 0\n",
    "    max_iterations = N * 100  # Prevent infinite loops\n",
    "    \n",
    "    while improved and iterations < max_iterations:\n",
    "        improved = False\n",
    "        best_delta = float('inf')  # Start with infinity, looking for best (most negative) improvement\n",
    "        best_idx = None\n",
    "        \n",
    "        # Try flipping each bit and find the best improvement\n",
    "        for i in range(N):\n",
    "            # Flip bit i\n",
    "            x_new = x.copy()\n",
    "            x_new[i] = 1 - x_new[i]\n",
    "            \n",
    "            # Compute energy difference: delta = E_new - E_old\n",
    "            # For minimization: negative delta = energy decreases = improvement\n",
    "            E_new = energy(x_new)\n",
    "            delta = E_new - E\n",
    "            \n",
    "            # Track the best improvement (most negative delta = largest energy decrease)\n",
    "            # Only accept moves that decrease energy (delta < 0) for minimization\n",
    "            if delta < best_delta and delta < 0:\n",
    "                best_delta = delta\n",
    "                best_idx = i\n",
    "                improved = True\n",
    "        \n",
    "        # Apply the best flip if it improves energy (decreases energy)\n",
    "        if improved and best_idx is not None and best_delta < 0:\n",
    "            x[best_idx] = 1 - x[best_idx]\n",
    "            E = energy(x)  # Recompute for accuracy\n",
    "            iterations += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return x, E\n",
    "\n",
    "# Run greedy algorithm\n",
    "start = time.perf_counter()\n",
    "x_greedy, E_greedy = greedy_optimize_qubo(mu, cov.values)\n",
    "elapsed_greedy = time.perf_counter() - start\n",
    "\n",
    "print(\"=== Greedy Algorithm result ===\")\n",
    "print(\"Bits (x*):\", x_greedy.tolist())\n",
    "print(\"Number of bets in portfolio:\", int(x_greedy.sum()))\n",
    "print(f\"Greedy energy: {E_greedy:.6f}\")\n",
    "print(f\"Time to find local optimum: {elapsed_greedy:.4f} seconds\")\n",
    "\n",
    "# Compare with brute force if available\n",
    "if \"results_df\" in globals():\n",
    "    greedy_bits = tuple(int(b) for b in x_greedy)\n",
    "    matches = results_df[results_df[\"x\"] == greedy_bits]\n",
    "    \n",
    "    if matches.empty:\n",
    "        print(\"\\nGreedy bitstring not found in brute-force table.\")\n",
    "        # Find closest energy in brute force results\n",
    "        energy_diff = np.abs(results_df[\"E\"] - E_greedy)\n",
    "        closest_idx = energy_diff.idxmin()\n",
    "        closest_rank = closest_idx + 1\n",
    "        E_best = results_df.loc[0, \"E\"]\n",
    "        print(f\"Closest brute-force energy: {results_df.loc[closest_idx, 'E']:.6f} (rank {closest_rank})\")\n",
    "        print(f\"Energy gap to ground state: {E_greedy - E_best:.6f}\")\n",
    "    else:\n",
    "        idx = matches.index[0]\n",
    "        rank = idx + 1\n",
    "        E_best = results_df.loc[0, \"E\"]\n",
    "        print(\"\\n=== Greedy vs Brute Force ===\")\n",
    "        print(f\"Rank of Greedy state among all 2^N configs: {rank} (1 = ground state)\")\n",
    "        print(f\"Ground state energy (brute force): {E_best:.6f}\")\n",
    "        print(f\"Energy gap to ground state: {E_greedy - E_best:.6f}\")\n",
    "\n",
    "# Compare with Simulated Annealing\n",
    "if \"x_sa\" in globals() and \"E_sa\" in globals():\n",
    "    print(\"\\n=== Greedy vs Simulated Annealing ===\")\n",
    "    print(f\"SA energy: {E_sa:.6f}\")\n",
    "    print(f\"Greedy energy: {E_greedy:.6f}\")\n",
    "    print(f\"Energy difference (Greedy - SA): {E_greedy - E_sa:.6f}\")\n",
    "    print(f\"SA time: {elapsed_sa:.4f} seconds\")\n",
    "    print(f\"Greedy time: {elapsed_greedy:.4f} seconds\")\n",
    "    print(f\"Speedup: {elapsed_sa / elapsed_greedy:.2f}x\")\n",
    "    \n",
    "    # Check if solutions are the same\n",
    "    if np.array_equal(x_greedy, x_sa):\n",
    "        print(\"Solutions are identical!\")\n",
    "    else:\n",
    "        print(f\"Solutions differ in {np.sum(x_greedy != x_sa)} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d8b43-b9f8-4d56-8c68-dadb3e0fc02d",
   "metadata": {},
   "source": [
    "## Summary and typical usage\n",
    "\n",
    "In this notebook we have:\n",
    "\n",
    "- Built a realistic **sportsbook portfolio optimisation** instance for a single football match.  \n",
    "- Encoded the problem as a **QUBO** where:\n",
    "  - linear terms reward high expected value bets,  \n",
    "  - quadratic terms penalise correlated / overlapping exposures.  \n",
    "- Exhaustively searched all \\(2^N\\) portfolios for a modest-sized universe (N ≈ 20) to obtain the **exact ground state**.\n",
    "- Mapped the QUBO to an **Ising model** and used **ORBIT** to approximately minimise the Ising energy.\n",
    "- Compared the ORBIT solution to the brute-force, simulated annealing and greedy optimums and inspected the selected portfolio of bets.\n",
    "- At scale, ORBIT simulator solution is the only one that can complete. Other algorithms struggle when dealing with 50+ markets.\n",
    "- Estimation of the ORBIT solution at scale is hard to make as the brute-force algorithm cannot be completed.\n",
    "- However, its ability to handle larger workloards than other methods makes it the strongest candidate algorithm for sports betting portfolio optimisation.\n",
    "\n",
    "For a typical user with more compute, the same pipeline can be applied to **larger sets of markets**:\n",
    "\n",
    "- The data feed would come from live sportsbook APIs rather than csv files of the previously saved API data.  \n",
    "- The correlation structure \\(cov\\) can incorporate more sophisticated measures of dependence between markets.  \n",
    "- ORBIT can be used to explore the energy landscape and propose **high-quality portfolios** within the user’s risk and bankroll constraints.\n",
    "\n",
    "This notebook is therefore intended as an **end-to-end, validated proof of concept** that a real combinatorial portfolio problem in sports betting can be:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qdchall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
